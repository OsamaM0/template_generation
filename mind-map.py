from flask import Flask, request, jsonify, render_template
from werkzeug.utils import secure_filename
import os
import requests
import fitz
import json
import textwrap
import logging
import base64
import re
from openai import OpenAI
from json_repair import repair_json

from dotenv import load_dotenv

load_dotenv()

app = Flask(__name__)

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# OpenAI Configuration
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')  # Set your OpenAI API key as environment variable
# MODEL_ID = "openai/gpt-oss-20b"  # Using the only available model on your RunPod endpoint
MODEL_ID = "gpt-4o-mini-2024-07-18"
# Initialize OpenAI client with shorter timeout for better error handling
client = OpenAI(api_key=OPENAI_API_KEY, 
                # base_url="https://mw68d46ydpbo0a-8000.proxy.runpod.net/v1",
                timeout=1000.0)  # Reduced timeout to 2 minutes


def extract_content_from_file(file):
    if file.filename.endswith('.pdf'):
        return extract_text_from_pdf(file)
    elif file.filename.endswith('.txt'):
        return file.read().decode('utf-8')
    else:
        raise ValueError("Unsupported file type")
    

def extract_text_from_pdf(pdf_file):
    text = ""
    try:
        pdf_document = fitz.open(stream=pdf_file.read(), filetype="pdf")
        for page_num in range(min(len(pdf_document), 10)):  # Limit to first 10 pages for performance
            page = pdf_document.load_page(page_num)
            page_text = page.get_text()
            text += page_text
            
        # Clean up common PDF extraction artifacts
        text = text.replace('\uf020', ' ').replace('\uf047', '')
        # Remove other Unicode artifacts that commonly appear in PDFs
        import re
        text = re.sub(r'[\uf000-\uf8ff]', '', text)  # Remove private use area characters
        text = ' '.join(text.split())  # Normalize whitespace
        
        logger.debug(f"Extracted {len(text)} characters from {min(len(pdf_document), 10)} pages")
        return text
    except Exception as e:
        logger.error(f"Error extracting PDF text: {e}")
        raise


def clean_and_parse_json(response_text):
    """
    Clean and parse JSON response from OpenAI API with multiple fallback strategies
    """
    logger.debug(f"Original response: {response_text[:200]}...")
    
    # Strategy 1: Remove markdown code blocks
    cleaned_text = re.sub(r'```json\s*', '', response_text)
    cleaned_text = re.sub(r'```\s*$', '', cleaned_text, flags=re.MULTILINE)
    
    # Strategy 2: Extract JSON from response if it contains other text
    json_match = re.search(r'(\{.*\})', cleaned_text, re.DOTALL)
    if json_match:
        cleaned_text = json_match.group(1)
    
    # Strategy 3: Remove any leading/trailing whitespace and non-JSON characters
    cleaned_text = cleaned_text.strip()
    
    # Strategy 4: Try to find the start and end of JSON object
    start_idx = cleaned_text.find('{')
    end_idx = cleaned_text.rfind('}')
    
    if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
        cleaned_text = cleaned_text[start_idx:end_idx + 1]
    
    logger.debug(f"Cleaned text: {cleaned_text[:200]}...")
    
    # Try parsing strategies in order of preference
    parsing_strategies = [
        # Strategy 1: Direct JSON parsing
        lambda text: json.loads(text),
        
        # Strategy 2: Use json-repair library
        lambda text: json.loads(repair_json(text)),
        
        # Strategy 3: Remove common formatting issues and try again
        lambda text: json.loads(
            text.replace('\n', ' ')
                .replace('\t', ' ')
                .replace('  ', ' ')
                .strip()
        ),
        
        # Strategy 4: Use json-repair on cleaned text
        lambda text: json.loads(repair_json(
            text.replace('\n', ' ')
                .replace('\t', ' ')
                .replace('  ', ' ')
                .strip()
        )),
    ]
    
    for i, strategy in enumerate(parsing_strategies):
        try:
            result = strategy(cleaned_text)
            logger.debug(f"Successfully parsed JSON using strategy {i + 1}")
            return result
        except (json.JSONDecodeError, ValueError) as e:
            logger.debug(f"Strategy {i + 1} failed: {e}")
            continue
    
    # If all strategies fail, log the error and raise exception
    logger.error(f"All JSON parsing strategies failed for text: {cleaned_text[:500]}")
    raise ValueError("Unable to parse response as valid JSON after trying multiple strategies")


def generate_mind_map(content):
    # Truncate content more aggressively for Arabic text which can be token-heavy
    max_content_length = 2000  # Reduced from 3000 for better performance with Arabic text
    if len(content) > max_content_length:
        content = content[:max_content_length] + "..."
        logger.debug(f"Content truncated to {max_content_length} characters")
    
    # Clean the content but don't escape braces since we're using f-strings
    content = content.strip()
    
    # Filter out some problematic characters that might cause issues
    import re
    content = re.sub(r'[\uf000-\uf8ff]', '', content)  # Remove private use area characters
    
    prompt = f"""
Ø£Ù†Øª Ø£Ø³ØªØ§Ø° ÙÙŠ Ø¹Ù„Ù… Ø§Ù„Ø¥Ø¯Ø±Ø§Ùƒ ÙˆØ®Ø¨ÙŠØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø±Ø§Ø¦Ø· Ø§Ù„Ø°Ù‡Ù†ÙŠØ© Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©. Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ© Ø´Ø§Ù…Ù„Ø© Ø¨ØµÙŠØºØ© JSON Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù…ÙƒØªØ¨Ø© GoJS Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚Ø¯Ù….

âš ï¸ Ù…Ù‡Ù… Ø¬Ø¯Ù‹Ø§: ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø±Ø¯Ùƒ ÙÙ‚Ø· Ø¹Ù„Ù‰ JSON ØµØ§Ù„Ø­. Ù„Ø§ ØªÙ‚Ù… Ø¨ØªØ¶Ù…ÙŠÙ† Ø£ÙŠ Ù†ØµÙˆØµ ØªÙØ³ÙŠØ±ÙŠØ© Ø£Ùˆ ØªÙ†Ø³ÙŠÙ‚Ø§Øª Markdown Ø£Ùˆ ÙƒØªÙ„ ÙƒÙˆØ¯. Ø§Ø¨Ø¯Ø£ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø§Ù„Ù‚ÙˆØ³ Ø§Ù„Ù…Ø¹Ù‚ÙˆÙ Ø§Ù„Ø§ÙØªØªØ§Ø­ÙŠ {{ ÙˆØ£Ù†Ù‡Ù Ø¨Ø§Ù„Ù‚ÙˆØ³ Ø§Ù„Ù…Ø¹Ù‚ÙˆÙ Ø§Ù„Ø®ØªØ§Ù…ÙŠ }}.

ÙŠÙ†Ø¨ØºÙŠ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ© Ù…ÙØµÙ„Ø© ÙˆØªØ´Ù…Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù‡Ù…Ø© Ø¯ÙˆÙ† Ø¥ØºÙØ§Ù„ Ø£ÙŠ ØªÙØ§ØµÙŠÙ„. Ø§Ù„ØªÙ‚Ø· Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆÙƒØ°Ù„Ùƒ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ø§Ø¹Ù…Ø©. Ù‚Ù… Ø¨ØªØ±ØªÙŠØ¨ Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ© ÙÙŠ Ø´ÙƒÙ„ Ù‡Ø±Ù…ÙŠ ÙŠÙØ¸Ù‡Ø± Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª ÙˆØ§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ø®ØªÙ„ÙØ©.

ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„ØµÙŠØºØ© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ù„Ù€ GoJS JSON Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ©:
{{
    "class": "go.TreeModel",
    "nodeDataArray": [
        {{"key":0, "text":"Mind Map", "loc":"0 0"}},
        {{"key":1, "parent":0, "text":"Getting more time", "brush":"skyblue", "dir":"right"}},
        {{"key":11, "parent":1, "text":"Wake up early", "brush":"skyblue", "dir":"right"}},
        {{"key":12, "parent":1, "text":"Delegate", "brush":"skyblue", "dir":"right"}},
        {{"key":2, "parent":0, "text":"More effective use", "brush":"darkseagreen", "dir":"right"}},
        {{"key":21, "parent":2, "text":"Planning", "brush":"darkseagreen", "dir":"right"}},
        {{"key":3, "parent":0, "text":"Time wasting", "brush":"palevioletred", "dir":"left"}},
        {{"key":31, "parent":3, "text":"Too many meetings", "brush":"palevioletred", "dir":"left"}}
    ]
}}

âš ï¸ Ù…Ù‡Ù… Ø¬Ø¯Ù‹Ø§: Ø­Ù„Ù‘Ù„ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ£Ù†Ø´Ø¦ Ø®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ© Ø§Ø³ØªÙ†Ø§Ø¯Ù‹Ø§ Ø¥Ù„Ù‰ Ù…Ø­ØªÙˆØ§Ù‡ Ø§Ù„ÙØ¹Ù„ÙŠ.
Ù„Ø§ ØªÙÙ†Ø´Ø¦ Ø®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ© Ø¹Ù† "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ÙˆÙ‚Øª" Ø£Ùˆ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø«Ø§Ù„ Ø£Ø¹Ù„Ø§Ù‡. Ø£Ù†Ø´Ø¦ Ø®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ© Ø§Ø³ØªÙ†Ø§Ø¯Ù‹Ø§ ÙÙ‚Ø· Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø­Ø¯Ø¯ Ø£Ø¯Ù†Ø§Ù‡:

{content}

Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:

1. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚Ø¯Ù… Ø£Ø¹Ù„Ø§Ù‡ ÙˆØ¶Ø¹Ù‡Ø§ ÙƒØ¹ÙÙ‚Ø¯ Ø£Ø³Ø§Ø³ÙŠØ©.
2. Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ø§Ø¹Ù…Ø©: Ù‚Ù… Ø¨ØªØ¶Ù…ÙŠÙ† Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ø§Ø¹Ù…Ø© ÙˆØ§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„ÙØ±Ø¹ÙŠØ© ÙƒØ¹ÙÙ‚Ø¯ ÙØ±Ø¹ÙŠØ© ØªØ­Øª Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©.
3. Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù‡Ø±Ù…ÙŠ: ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ© ØªØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ù‡ÙŠÙƒÙ„ Ù‡Ø±Ù…ÙŠ ÙˆØ§Ø¶Ø­.
4. Ø¹Ø¯Ù… Ø¥ØºÙØ§Ù„ Ø§Ù„ØªÙØ§ØµÙŠÙ„: Ù„Ø§ ØªÙ‡Ù…Ù„ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ù‡Ù…Ø©.
5. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©: Ø§Ø³ØªØ¹Ù…Ù„ Ø£Ù„ÙˆØ§Ù†Ù‹Ø§ Ù…Ø®ØªÙ„ÙØ© Ù„Ù„ØªÙ…ÙŠÙŠØ² Ø¨ÙŠÙ† Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ù‡Ø±Ù…ÙŠ.
6. ØµÙŠØºØ© JSON ØµØ§Ù„Ø­Ø© ÙÙ‚Ø·: Ø£Ø¹Ø¯ ÙÙ‚Ø· JSON ØµØ§Ù„Ø­Ù‹Ø§ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ ØªÙ†Ø³ÙŠÙ‚Ø§Øª Markdown Ø£Ùˆ Ù†ØµÙˆØµ ØªÙØ³ÙŠØ±ÙŠØ©.
7. Ø­Ø±Ø¬: ÙŠØ¬Ø¨ Ø£Ù† ØªÙØ¨Ù†Ù‰ Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ© ÙÙ‚Ø· Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚Ø¯Ù… Ø£Ø¹Ù„Ø§Ù‡ØŒ ÙˆÙ„ÙŠØ³ Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ø«Ø§Ù„.

ðŸ“Œ Ø£Ø¹Ø¯ Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ© Ø¨ØµÙŠØºØ© JSON Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø§Ø³ØªÙ†Ø§Ø¯Ù‹Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ Ø§Ù„Ù…Ù‚Ø¯Ù….
"""

    
    try:
        logger.debug(f"Sending request to model: {MODEL_ID}")
        logger.debug(f"Content being processed: {content[:300]}...")
        logger.debug(f"Full prompt length: {len(prompt)} characters")
        
        # Log a snippet to verify content is included
        logger.debug(f"Prompt includes actual content: {'=== IMPORTANT:' in prompt}")
        
        response = client.chat.completions.create(
            model=MODEL_ID,
            messages=[
                {"role": "system", "content": "You are an expert at creating detailed mind maps in JSON format. You must analyze the PROVIDED TEXT CONTENT and create a mind map based on that specific content, not on any examples given."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,  # Reduced temperature for more consistent results
            top_p=0.9,       # Reduced top_p for more focused responses
            max_tokens=8192  # Limit response length to prevent timeouts
        )
        response_text = response.choices[0].message.content
        logger.debug(f"Raw API response: {response_text[:200]}...")
        print(response_text)
        # Use the enhanced parsing function
        mind_map_data = clean_and_parse_json(response_text)
        logger.debug(f"Successfully parsed mind map data with {len(mind_map_data.get('nodeDataArray', []))} nodes")
        
        return mind_map_data
    except Exception as e:
        logger.error(f"Error generating mind map: {e}")
        logger.error(f"Full error details: {str(e)}")
        raise

def translate_mind_map(content):
    # Truncate content if it's too long to prevent token overflow
    max_content_length = 3000  # Adjust based on model's context window
    if len(content) > max_content_length:
        content = content[:max_content_length] + "..."
        logger.debug(f"Translation content truncated to {max_content_length} characters")
    
    prompt = """JesteÅ› profesorem nauk lingwistycznych, twoich zadaniem jest przetÅ‚umaczyÄ‡ zawartoÅ›Ä‡ tekstowÄ… podanej mapy myÅ›li na jÄ™zyk Polski, nie naruszajÄ…c struktury mapy.
    
    KRYTYCZNE: Twoja odpowiedÅº musi zawieraÄ‡ TYLKO poprawny JSON. Nie doÅ‚Ä…czaj Å¼adnego tekstu wyjaÅ›niajÄ…cego, formatowania markdown, ani blokÃ³w kodu. Zacznij bezpoÅ›rednio od otwierajÄ…cego nawiasu klamrowego {{ i zakoÅ„cz zamykajÄ…cym nawiasem klamrowym }}.
    
    Wykorzystane sÅ‚ownictwo powinno posiadaÄ‡ wydÅºwiÄ™k podobny do oryginalnego tekstu. ZwrÃ³Ä‡ nienaruszonÄ… w strukturze mapÄ™ myÅ›li z przetumaczonÄ… zawartoÅ›ciÄ… w formacie JSON.
    Oryginalne, angielskie wersje nazw wÅ‚asnych i naukowych pozostawiaj w nawiasach obok tÅ‚umaczenia. 

    Mapa myÅ›li do przetÅ‚umaczenia:
    {content}
    """

    formatted_prompt = textwrap.dedent(prompt).format(content=content)
    logger.debug(f"Formatted translation prompt length: {len(formatted_prompt)} characters")
    
    try:
        response = client.chat.completions.create(
            model=MODEL_ID,
            messages=[
                {"role": "system", "content": "You are an expert linguist specializing in Polish translation while preserving JSON structure."},
                {"role": "user", "content": formatted_prompt}
            ],
            temperature=0.3,
            top_p=0.95
        )
        response_text = response.choices[0].message.content
        logger.debug(f"Raw translation response: {response_text[:200]}...")
        
        # Use the enhanced parsing function
        translated_data = clean_and_parse_json(response_text)
        logger.debug(f"Successfully parsed translated mind map data with {len(translated_data.get('nodeDataArray', []))} nodes")
        
        return translated_data
    except Exception as e:
        logger.error(f"Error translating mind map: {e}")
        raise
    

@app.route('/')
def index():
    logger.debug("Rendering index page")
    return render_template('index.html')


@app.route('/generate', methods=['POST'])
def generate():
    logger.debug("Received a request to generate a mind map.")

    file = request.files.get('file')
    text = request.form.get('text')

    logger.debug(f"File received: {file.filename if file else 'None'}")
    logger.debug(f"Text received: {text[:100] if text else 'None'}...")

    if file:
        try:
            filename = secure_filename(file.filename)
            logger.debug(f"Processing file: {filename}")

            file_content = extract_content_from_file(file)
            logger.debug(f"Extracted content length: {len(file_content)} characters")
            logger.debug(f"Content preview: {file_content[:300]}...")
            
            mind_map_data = generate_mind_map(file_content)
            logger.debug(f"Generated mind map with {len(mind_map_data.get('nodeDataArray', []))} nodes")

            # Log the actual content of the first few nodes to verify it's from the uploaded file
            nodes = mind_map_data.get('nodeDataArray', [])
            if nodes:
                logger.debug(f"Root node text: {nodes[0].get('text', 'N/A')}")
                if len(nodes) > 1:
                    logger.debug(f"First child node text: {nodes[1].get('text', 'N/A')}")

            return jsonify(mind_map_data)
        except Exception as e:
            logger.error(f"Error processing uploaded file: {e}")
            return jsonify({'error': str(e)}), 500
    elif text:
        try:
            logger.debug(f"Processing text input: {text[:50]}...")
            mind_map_data = generate_mind_map(text)
            return jsonify(mind_map_data)
        except Exception as e:
            logger.error(f"Error processing text input: {e}")
            return jsonify({'error': str(e)}), 500
    else:
        return jsonify({'error': 'No file or text input provided'}), 400
    

@app.route('/translate', methods=['POST'])
def translate():
    logger.debug("Received a request to translate a mind map.")

    try:
        request_data = request.get_json()
        mind_map_content = request_data.get('content')

        if not mind_map_content:
            return jsonify({'error': 'Mind map content not provided'}), 400

        # Convert the content to JSON string if it's a dict
        if isinstance(mind_map_content, dict):
            content_str = json.dumps(mind_map_content, ensure_ascii=False)
        else:
            content_str = str(mind_map_content)

        translated_data = translate_mind_map(content_str)
        logger.debug(f"Translated data with {len(translated_data.get('nodeDataArray', []))} nodes")

        return jsonify(translated_data)
    except Exception as e:
        logger.error(f"Error translating mind map: {e}")
        return jsonify({'error': 'Internal server error'}), 500
    

@app.route('/load_map', methods=['POST'])
def load_map():
    file = request.files['file']
    if file:
        try:
            map_data = json.load(file)
            logger.debug(f"Loaded mind map data: {map_data}")
            return jsonify(map_data), 200
        except Exception as e:
            logger.error(f"Error loading mind map: {e}")
            return jsonify({'error': str(e)}), 500
    logger.warning("No file uploaded")
    return jsonify({'error': 'No file uploaded'}), 400


@app.route('/test_generate', methods=['GET'])
def test_generate():
    """Test endpoint to verify mind map generation with sample text"""
    logger.debug("Test generate endpoint called")
    
    sample_text = """
    Project Management Fundamentals
    
    Project management is the practice of initiating, planning, executing, controlling, and closing the work of a team to achieve specific goals and meet specific success criteria at the specified time.
    
    Key Areas:
    1. Project Planning - Defining scope, timeline, and resources
    2. Risk Management - Identifying and mitigating potential issues
    3. Team Leadership - Managing and motivating team members
    4. Quality Control - Ensuring deliverables meet standards
    5. Budget Management - Controlling costs and resource allocation
    
    Success Factors:
    - Clear communication
    - Stakeholder engagement
    - Regular monitoring and reporting
    - Adaptability to change
    """
    
    try:
        logger.debug(f"Generating mind map for sample text: {len(sample_text)} characters")
        mind_map_data = generate_mind_map(sample_text)
        logger.debug(f"Generated test mind map with {len(mind_map_data.get('nodeDataArray', []))} nodes")
        
        # Log some details about the generated map
        nodes = mind_map_data.get('nodeDataArray', [])
        if nodes:
            logger.debug(f"Root node: {nodes[0]}")
            
        return jsonify(mind_map_data)
    except Exception as e:
        logger.error(f"Error in test generate: {e}")
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    if not OPENAI_API_KEY:
        logger.error("OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.")
        exit(1)
    
    logger.debug(f"Initialized OpenAI client with model: {MODEL_ID}")
    app.run(host='0.0.0.0', port=8081, debug=False)
